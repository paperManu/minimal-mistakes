---
layout: post
title: Splash, a projection mapping software
description: "Introducing Splash, a multi-projector mapping software"
modified: 2014-05-19
image:
    feature: splash/color_map.jpg
---

While working at the Metalab, the research team of the [SAT](http://sat.qc.ca), we faced a few limitations with the hardware driving the fulldome located their (the [Satosphere](http://sat.qc.ca/en/satosphere)). The main one being that as a research laboratory, we need to be able to have full control over our devices, which is obviously not always compatible with proprietary software and hardware. Also we had to deal for some time with the maximum resolution for real-time inputs, and we wanted to get rid of it.

<figure>
    <img src="{{ site.url }}/images/splash/fullscreen.jpg">
</figure>

So [Splash](http://github.com/paperManu/splash) was initiated. Splash is made to handle configurations like the Satosphere with a single computer, provided that it has a powerful enough cpu (Core i7 or so) and eight video outputs. Obviously, not everybody need eight outputs, and I have good results with a Core i5 and a GTX670 on four outputs. Splash is configurable so as to handle as many outputs as you can on a single computer, and is not limited to fulldomes: as long as you have the 3D model of the projection surface, it should do the job. If not, help me making this software better by telling me !

<figure>
    <img src="{{ site.url }}/images/splash/four_outputs.jpg">
</figure>

On an architectural note, Splash is built around OpenGL with the help of [GLFW](http://www.glfw.org). The majority of the video flow is configurable, from the input (which currently has to be a shared memory fed through [Shmdata](http://code.sat.qc.ca/libshmdata)). To handle the fact that GLFW can only output to one single display adapter at a time, an instance of Splash is made of multiple processes: a main process which handles inputs and configuration, and child processes for each adapter. Communication between them is done through shared memories (again), this time using [ZeroMQ](http://www.zeromq.org). The idea behind the use of ZeroMQ instead of Shmdata is that, in a hopefully not so distant future, it will be possible to have processes on different computers working together for one massive mapping.

<figure class="half">
    <img src="{{ site.url }}/images/splash/dome_color_map.jpg">
    <img src="{{ site.url }}/images/splash/dome_wireframe.jpg">
</figure>

The documentation provided in the repository gives (I hope) enough information on how to use it, although some features need to be explained and illustrated more thoroughly, like the semi-automatic calibration. It works by considering that each projector is linked to a virtual camera, so the calibration problem is indeed a 3D - 2D correspondance problem. An algorithm to solve this is available in OpenCV (solvePnP and solvePnPRansac), but I needed to also guess the field of view and the x and y shifts of the projector, so I implemented my own reprojection error minimization method with the help of the [GNU Scientific Library](https://www.gnu.org/software/gsl).

Splash is already packaged for Ubuntu / Mint / other compatible distribution, you only have to follow the installation instructions in the README.md. If you happen to use this software in your project, please tell me, even if you stumbled upon some limitations. Splash is meant to evolve, mainly to follow our research program, but I want to improve it any way which makes sense.
